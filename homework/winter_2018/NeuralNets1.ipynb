{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fashion_mnist_master.utils import mnist_reader\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import fashion_mnist as fmn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "Build a fully connected neural network in Keras to classify the images in Fashion-MNIST using one hidden layer of 5 neurons and a softmax output layer.  So the structure is \n",
    "\n",
    "    x_1             a_1\n",
    "    x_2             a_2\n",
    "    x_3             a_3\n",
    "    .               a_4                softmax\n",
    "    .               a_5\n",
    "    .\n",
    "    .\n",
    "    x_728\n",
    "    \n",
    "where every $x_i$ is connected to every $a_i$, and every $a_i$ is connected to the softmax. Each $x_i$ corresponds to one pixel in an input image and each $a_i$ is a \"hidden\" neuron.  (note that the fashion-MNIST dataset is available in Keras: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "x_train, y_train = mnist_reader.load_mnist('fashion_mnist_master/data/fashion', kind='train')\n",
    "x_test, y_test = mnist_reader.load_mnist('fashion_mnist_master/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build and train the network using ReLU as the activation function for the hidden layer.\n",
    "2. Build and train the network again using sigmoid as the activation function for the hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "relu = Sequential()\n",
    "relu.add (Dense(5, input_dim=x_train.shape[1], activation='relu'))\n",
    "relu.add(Dense(10, activation='softmax'))\n",
    "relu.compile(loss='categorical_crossentropy', \n",
    "             optimizer='adam', metrics=['accuracy'])\n",
    "relu.fit(x_train, y_train, epochs=40, verbose=0, \n",
    "                       batch_size=x_train.shape[0], initial_epoch=0)\n",
    "\n",
    "relu_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sigmoid = Sequential()\n",
    "sigmoid.add(Dense(5,input_dim=x_train.shape[1], activation='sigmoid'))\n",
    "sigmoid.add(Dense(10,activation='softmax'))\n",
    "sigmoid.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam', metrics=['accuracy'])\n",
    "sigmoid.fit(x_train, y_train, epochs=40, verbose=0, \n",
    "            batch_size=x_train.shape[0], initial_epoch=0)\n",
    "sigmoid_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_result = relu.evaluate(x_test, y_test, verbose=0)[1]\n",
    "sigmoid_result = sigmoid.evaluate(x_test, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tACCURACY\tTIME\n",
      "ReLU\t0.4025\t\t15.131405591964722\n",
      "Sigmoid\t0.1792\t\t15.115326166152954\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tACCURACY\\tTIME\")\n",
    "print(\"ReLU\\t{}\\t\\t{}\".format(relu_result, relu_time))\n",
    "print(\"Sigmoid\\t{}\\t\\t{}\".format(sigmoid_result, sigmoid_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the training time and the accuracy of your two neural network to each other and to the training time and accuracy of the XGBoost classifier you built previously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Results:<br><br>\n",
    "Best parameters: <br> \n",
    "gamma: 0.6666666666666666 <br>\n",
    "learning_rate: 0.7 <br><br>\n",
    "Best Score: 0.8898\n",
    "\n",
    "I didn't record how long the XGBoost took to train but I know it was WAAAAAY longer than these neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
