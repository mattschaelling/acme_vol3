{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Write a binary naive Bayes classifier from scratch to classify data that has normally distributed features ($x$) and binary outputs ($y$). Take care to prevent underflow in the very tiny products that occur in the intermediate computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_naive_bayes(x, y):\n",
    "    '''\n",
    "    this function accepts training data x and y\n",
    "    then returns a new function that will classify\n",
    "    any new data x. Assumes each feature is normally\n",
    "    distributed.\n",
    "    \n",
    "    n - number of observations\n",
    "    d - number of features\n",
    "    x is an nxd array of normally distributed features\n",
    "    y is an nx1 array of ones and zeros\n",
    "    '''\n",
    "    # y=1\n",
    "    x1 = x[y==1]\n",
    "    mu1 = []\n",
    "    sigma1 = []\n",
    "    for i in range(len(x1[0])):\n",
    "        mu1.append(x1[:,i].mean())\n",
    "        sigma1.append(x1[:,i].std())\n",
    "    \n",
    "    # y=0\n",
    "    x0 = x[y==0]\n",
    "    mu0 = []\n",
    "    sigma0 = []\n",
    "    for i in range(len(x1[0])):\n",
    "        mu0.append(x0[:,i].mean())\n",
    "        sigma0.append(x0[:,i].std())\n",
    "        \n",
    "    # create classifying fuction\n",
    "    def classifier(Xtest):\n",
    "        yhat = []\n",
    "        for x in Xtest:\n",
    "            # classify probability of y=0\n",
    "            logprob0 = 0\n",
    "            for k in range(len(x)):\n",
    "                logprob0 += np.log(stats.norm.pdf(x[k], mu0[k], sigma0[k]))\n",
    "            prob0 = np.exp(logprob0)*(1-y.mean())\n",
    "\n",
    "            # classify probability of y=1\n",
    "            logprob1 = 0\n",
    "            for k in range(len(x)):\n",
    "                logprob1 += np.log(stats.norm.pdf(x[k], mu1[k], sigma1[k]))\n",
    "            prob1 = np.exp(logprob1)*y.mean()\n",
    "\n",
    "            yhat.append(np.argmax([prob0, prob1]))\n",
    "        return np.array(yhat)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Apply your classifier to the `scikit-learn` cancer data set with a 70-30 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:42: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.93984962406\n",
      "Training Time:\t0.00445578573181\n"
     ]
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "X,y = cancer.data, cancer.target\n",
    "xtrain, xtest, ytrain, ytest = ms.train_test_split(X,y, test_size = .7)\n",
    "\n",
    "start = time.clock()\n",
    "trained_model = binary_naive_bayes(xtrain, ytrain)\n",
    "my_train_time = time.clock() - start\n",
    "\n",
    "print(\"Accuracy:\\t{}\".format((trained_model(xtest)==ytest).mean()))\n",
    "print(\"Training Time:\\t{}\".format(my_train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Compare your results (training time and test accuracy) to the `scikit-learn` naive bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.937343358396\n",
      "Training Time:\t0.00127384354073\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "start = time.clock()\n",
    "gnb.fit(xtrain, ytrain)\n",
    "sklearn_train_time = time.clock() - start\n",
    "\n",
    "print(\"Accuracy:\\t{}\".format((gnb.predict(xtest)==ytest).mean()))\n",
    "print(\"Training Time:\\t{}\".format(sklearn_train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that Scikit Learn's training time is quicker than mine by about a factor of 4, but my accuracy is ever so slightly higher. This I am proud of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
