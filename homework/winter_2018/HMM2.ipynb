{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import codecs\n",
    "from itertools import product\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from HMM packet \n",
    "## Problem 2a\n",
    "\n",
    "For this problem, use the same model   and observation sequence O given in Problem 1.\n",
    "\n",
    "The model is $λ = (A, B, π)$ where\n",
    "$A = \n",
    "\\begin{bmatrix}\n",
    "0.7 & 0.3 \\\\\n",
    "0.4 & 0.6\n",
    "\\end{bmatrix}$\n",
    ", $B =\n",
    "\\begin{bmatrix}\n",
    "0.1 &0.4& 0.5 \\\\\n",
    "0.7 &0.2 &0.1\n",
    "\\end{bmatrix}$\n",
    ", $π =\n",
    "\\begin{bmatrix}\n",
    "0.0& 1.0\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "Furthermore, suppose the hidden states correspond to $H$ and $C$, respectively, and the observations are $S$, $M$, and $L$, respectively. In this problem, we consider the observation sequence $O = (O_0, O_1, O_2) = (M, S, L)$.\n",
    "\n",
    "\n",
    "a) Determine the “best” hidden state sequence (X0, X1, X2) in the dynamic program- ming sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0168\n",
      "{'C0': 0.20000000000000001,\n",
      " 'C1': 0.083999999999999991,\n",
      " 'C2': 0.0050399999999999993,\n",
      " 'H0': 0.0,\n",
      " 'H1': 0.0080000000000000019,\n",
      " 'H2': 0.016799999999999999}\n"
     ]
    }
   ],
   "source": [
    "A1 = np.array([[.7,.3],\n",
    "              [.4,.6]])\n",
    "B1 = np.array([[.1,.4,.5],\n",
    "              [.7,.2,.1]])\n",
    "pi1 = np.array([0., 1.])\n",
    "Obs = np.array([1,0,2])\n",
    "states = ['H','C']\n",
    "path_probs = dict()\n",
    "\n",
    "N = 2\n",
    "M = 3\n",
    "T = 3\n",
    "\n",
    "delta = np.zeros((T,N))\n",
    "for i in range(N):\n",
    "    delta[0,i] = pi1[i]*B1[i,Obs[0]]\n",
    "    path_probs[states[i]+'0'] = delta[0,i]\n",
    "\n",
    "for t in range(1,3):\n",
    "    for i in range(N):\n",
    "        delta[t,i] = np.max(delta[t-1]*A1[:,i]*B1[i,Obs[t]])\n",
    "        path_probs[states[i]+str(t)] = delta[t,i]\n",
    "        #for j in range(N):\n",
    "        #    alpha[t,i] = alpha[t,i] + alpha[t-1,j]*A1[j,i]\n",
    "        #alpha[t,i] = alpha[t,i]*B1[i,Obs[t]]\n",
    "prob = delta[-1].max()\n",
    "print(prob)\n",
    "pprint(path_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So optimal path is CCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Write the re-estimation formulae (9), (10) and (11) directly in terms of $\\alpha$ and $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(9) $\\pi_i = \\gamma_0(i) = \\frac{\\alpha_0(i)\\beta_0(i)}{P(O|\\lambda)}$ <br>\n",
    "(10) $a_{ij} = \\sum_{t=0}^{T-2}\\gamma_t(i,j) / \\sum_{t=0}^{T-2}\\gamma_t(i) = \\sum_{t=0}^{T-2}\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j) / \\sum_{t=0}^{T-2}\\sum_{j=0}^{N-1}\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j) $ <br>\n",
    "(11) $b_j(k) = \\sum_{t\\in{0,1,...,T-1}; O_t=k} \\sum_{j=0}^{N-1}\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j) / \\sum_{t=0}^{T-1} \\sum_{j=0}^{N-1}\\alpha_t(i)a_{ij}b_j(O_{t+1})\\beta_{t+1}(j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from Discrete Hidden Markov Models (lab 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class hmm():\n",
    "    def __init__(self, A=None, B=None, pi=None):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "        \n",
    "    def _forward(self, obs):\n",
    "        \"\"\"\n",
    "        Compute the scaled forward probability matrix and scaling factors.\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : ndarray of shape (T,)\n",
    "        The observation sequence\n",
    "        Returns\n",
    "        -------\n",
    "        alpha : ndarray of shape (T,N)\n",
    "        The scaled forward probability matrix\n",
    "        c : ndarray of shape (T,)\n",
    "        The scaling factors c = [c_1,c_2,...,c_T]\n",
    "        \"\"\"\n",
    "        A = self.A\n",
    "        B = self.B\n",
    "        pi = self.pi\n",
    "        T = len(obs)\n",
    "        N = self.A.shape[0]\n",
    "        alpha = np.zeros((T,N))\n",
    "        c = np.zeros(T)\n",
    "        c[0] = 1./np.dot(pi,B[obs[0]])\n",
    "        alpha[0] = c[0]*(pi*B[obs[0]])\n",
    "        for t in range(1,T):\n",
    "            c[t] = 1./np.dot(A.dot(alpha[t-1]),B[obs[t]])\n",
    "            alpha[t] = c[t]*(A.dot(alpha[t-1])*B[obs[t]])\n",
    "        return alpha, c\n",
    "            \n",
    "        \n",
    "    def _backward(self, obs, c):\n",
    "        \"\"\"\n",
    "        Compute the scaled backward probability matrix.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : ndarray of shape (T,)\n",
    "        The observation sequence\n",
    "        c : ndarray of shape (T,)\n",
    "        The scaling factors from the forward pass\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        beta : ndarray of shape (T,N)\n",
    "        The scaled backward probability matrix\n",
    "        \"\"\"\n",
    "        A = self.A\n",
    "        B = self.B\n",
    "        pi = self.pi\n",
    "        T = len(obs)\n",
    "        N = A.shape[0]\n",
    "        beta = np.zeros((T,N))\n",
    "        beta[-1] = c[-1]\n",
    "        for t in range(T-2,-1,-1):\n",
    "            beta[t] = c[t]*(A.T).dot(B[obs[t+1]]*beta[t+1])\n",
    "        return beta\n",
    "    \n",
    "    def _delta(self, obs, alpha, beta):\n",
    "        \"\"\"\n",
    "        Compute the delta probabilities.\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : ndarray of shape (T,)\n",
    "        The observation sequence\n",
    "        alpha : ndarray of shape (T,N)\n",
    "        The scaled forward probability matrix from the forward pass\n",
    "        beta : ndarray of shape (T,N)\n",
    "        The scaled backward probability matrix from the backward pass\n",
    "        Returns\n",
    "        -------\n",
    "        delta : ndarray of shape (T-1,N,N)\n",
    "        The delta probability array\n",
    "        gamma : ndarray of shape (T,N)\n",
    "        The gamma probability array\n",
    "        \"\"\"\n",
    "        A = self.A\n",
    "        B = self.B\n",
    "        T = len(obs)\n",
    "        N = A.shape[0]\n",
    "        delta = np.zeros((T-1, N, N))\n",
    "        gamma = np.zeros((T,N))\n",
    "        for t in range(0,T-1):\n",
    "            denominator = np.sum([alpha[t,k]*A[l,k]*B[obs[t+1],l]*beta[t+1,l] \n",
    "                                  for l,k in product(range(N),repeat=2)])\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    delta[t,i,j] = alpha[t,i]*A[j,i]*B[obs[t+1],j]\\\n",
    "                                    *beta[t+1,j]/denominator\n",
    "                gamma[t,i] = delta[t,i,:].sum()\n",
    "        gamma[-1] = alpha[-1]*beta[-1]/alpha[-1].dot(beta[-1])\n",
    "        return delta, gamma\n",
    "    \n",
    "    def _estimate(self, obs, delta, gamma):\n",
    "        \"\"\"\n",
    "        Estimate better parameter values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : ndarray of shape (T,)\n",
    "        The observation sequence\n",
    "        delta : ndarray of shape (T-1,N,N)\n",
    "        The delta probability array\n",
    "        gamma : ndarray of shape (T,N)\n",
    "        The gamma probability array\n",
    "        \"\"\"\n",
    "        # update self.A, self.B, self.pi in place\n",
    "        T = len(obs)\n",
    "        N = self.A.shape[0]\n",
    "        self.A = delta.sum(axis=0).T/gamma[:T-1].sum(axis=0)\n",
    "        self.B = np.zeros_like(self.B)\n",
    "        for i in range(self.B.shape[0]):\n",
    "            self.B[i] = gamma[obs==i,:].sum(axis=0)/gamma.sum(axis=0)\n",
    "        self.pi = gamma[0]\n",
    "        \n",
    "    # add fit method\n",
    "    def fit(self, obs, A, B, pi, max_iter=100, tol=1e-3):\n",
    "        \"\"\"\n",
    "        Fit the model parameters to a given observation sequence.\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : ndarray of shape (T,)\n",
    "        Observation sequence on which to train the model.\n",
    "        A : stochastic ndarray of shape (N,N)\n",
    "        Initialization of state transition matrix\n",
    "        B : stochastic ndarray of shape (M,N)\n",
    "        Initialization of state observation matrix\n",
    "        pi : stochastic ndarray of shape (N,)\n",
    "        Initialization of initial state distribution\n",
    "        max_iter : integer\n",
    "        The maximum number of iterations to take\n",
    "        tol : float\n",
    "        The convergence threshold for change in log-probability\n",
    "        \"\"\"\n",
    "        # initialize self.A, self.B, self.pi\n",
    "        self.A, self.B, self.pi = A, B, pi\n",
    "        \n",
    "        # run the iterations\n",
    "        logprob0 = 1 # initializing logprob to something it couldn't be\n",
    "        for i in range(max_iter):\n",
    "            alpha, c = self._forward(obs)\n",
    "            logprob1 = -1*c.sum()\n",
    "            if np.abs(logprob1 - logprob0) < tol:\n",
    "                break\n",
    "            beta = self._backward(obs,c)\n",
    "            delta, gamma = self._delta(obs, alpha, beta)\n",
    "            self._estimate(obs, delta, gamma)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# toy HMM example to be used to check answers\n",
    "A = np.array([[.7, .4],\n",
    "              [.3, .6]])\n",
    "B = np.array([[.1,.7],\n",
    "              [.4, .2],\n",
    "              [.5, .1]])\n",
    "pi = np.array([.6, .4])\n",
    "obs = np.array([0, 1, 0, 2])\n",
    "\n",
    "h = hmm()\n",
    "h.A = A\n",
    "h.B = B\n",
    "h.pi = pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.6429135909\n"
     ]
    }
   ],
   "source": [
    "alpha, c = h._forward(obs)\n",
    "print(-1*(np.log(c)).sum()) # the log prob of observation\n",
    "# Expected output should be -4.6429135909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.1361635   2.89939354]\n",
      " [ 2.86699344  4.39229044]\n",
      " [ 3.898812    2.66760821]\n",
      " [ 3.56816483  3.56816483]]\n"
     ]
    }
   ],
   "source": [
    "beta = h._backward(obs, c)\n",
    "print(beta)\n",
    "# Expected output:\n",
    "# [[ 3.1361635 2.89939354]\n",
    "# [ 2.86699344 4.39229044]\n",
    "# [ 3.898812 2.66760821]\n",
    "# [ 3.56816483 3.56816483]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Added methods to compute $\\delta$ and $\\gamma$ to my class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.14166321  0.0465066 ]\n",
      "  [ 0.37776855  0.43406164]]\n",
      "\n",
      " [[ 0.17015868  0.34927307]\n",
      "  [ 0.05871895  0.4218493 ]]\n",
      "\n",
      " [[ 0.21080834  0.01806929]\n",
      "  [ 0.59317106  0.17795132]]]\n",
      "[[ 0.18816981  0.81183019]\n",
      " [ 0.51943175  0.48056825]\n",
      " [ 0.22887763  0.77112237]\n",
      " [ 0.8039794   0.1960206 ]]\n"
     ]
    }
   ],
   "source": [
    "delta, gamma = h._delta(obs, alpha, beta)\n",
    "print(delta)\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "\n",
    "Added a parameter updating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55807991  0.49898142]\n",
      " [ 0.44192009  0.50101858]]\n",
      "\n",
      "[[ 0.23961928  0.70056364]\n",
      " [ 0.29844534  0.21268397]\n",
      " [ 0.46193538  0.08675238]]\n",
      "\n",
      "[ 0.18816981  0.81183019]\n"
     ]
    }
   ],
   "source": [
    "h._estimate(obs,delta,gamma)\n",
    "print(h.A)\n",
    "print('')\n",
    "print(h.B)\n",
    "print('')\n",
    "print(h.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Implement the learning algorithm by adding the following method to your hmm class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_random(N,M,sigma = .01):\n",
    "    A = np.random.randn(N,N)*sigma + 1./N\n",
    "    A[:,-1] = 1. - A[:,:-1].sum(axis=1)\n",
    "    B = np.random.randn(M,N)*sigma + 1./N\n",
    "    B[:,-1] = 1. - B[:,:-1].sum(axis=1)\n",
    "    pi = np.random.randn(N)*sigma + 1./N\n",
    "    return A,B,pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# added the fit method to my class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "\n",
    "You are now ready to train a HMM using the Declaration of Independence data.\n",
    "Use N = 2 states and M =len(set(obs))= 27 observation values (26 lower case characters\n",
    "and 1 whitespace character), and run for 200 iterations with the default value for tol. Generally\n",
    "speaking, if you converge to a log probability greater than 21550,\n",
    "then you have reached an\n",
    "acceptable set of parameters for this dataset.\n",
    "Once the learning algorithm converges, analyze the state observation matrix B. Note\n",
    "which rows correspond to the largest and smallest probability values in each column of B, and\n",
    "check the corresponding characters. The code below displays typical results for a well-converged\n",
    "HMM. Note that the u before the \" indicates that the string should be unicode, which will be\n",
    "required for languages other than English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_translate(a, my_dict):\n",
    "    # translate numpy array from symbols to state numbers or vice versa\n",
    "    return np.vectorize(my_dict.__getitem__)(a)\n",
    "\n",
    "def prep_data(filename):\n",
    " \n",
    "    # Get the data as a single string\n",
    "    with codecs.open(filename, encoding='utf-8') as f:\n",
    "        data=f.read().lower() #and convert to all lower case\n",
    "        \n",
    "    # remove punctuation and newlines\n",
    "    remove_punct_map = {ord(char): None for char in string.punctuation+\"\\n\\r\"}\n",
    "    data = data.translate(remove_punct_map)\n",
    "    \n",
    "    # make a list of the symbols in the data\n",
    "    symbols = sorted(list(set(data)))\n",
    "    \n",
    "    # convert the data to a NumPy array of symbols\n",
    "    a = np.array(list(data))\n",
    "    \n",
    "    #make a conversion dictionary from symbols to state numbers\n",
    "    symbols_to_obsstates = {x:i for i,x in enumerate(symbols)}\n",
    "    \n",
    "    #convert the symbols in a to state numbers\n",
    "    obs_sequence = vec_translate(a,symbols_to_obsstates)\n",
    "    \n",
    "    return symbols, obs_sequence\n",
    "\n",
    "     \n",
    "symbols, obs = prep_data('declaration.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "M = len(set(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.0027, 0.3308\n",
      "a, 0.0000, 0.1231\n",
      "b, 0.0240, 0.0000\n",
      "c, 0.0466, 0.0000\n",
      "d, 0.0638, 0.0000\n",
      "e, 0.0000, 0.2217\n",
      "f, 0.0455, 0.0000\n",
      "g, 0.0329, 0.0000\n",
      "h, 0.0741, 0.0145\n",
      "i, 0.0000, 0.1159\n",
      "j, 0.0040, 0.0000\n",
      "k, 0.0030, 0.0005\n",
      "l, 0.0570, 0.0007\n",
      "m, 0.0364, 0.0000\n",
      "n, 0.1213, 0.0009\n",
      "o, 0.0010, 0.1315\n",
      "p, 0.0349, 0.0000\n",
      "q, 0.0015, 0.0000\n",
      "r, 0.1075, 0.0000\n",
      "s, 0.1209, 0.0000\n",
      "t, 0.1619, 0.0000\n",
      "u, 0.0000, 0.0540\n",
      "v, 0.0187, 0.0000\n",
      "w, 0.0245, 0.0000\n",
      "x, 0.0023, 0.0000\n",
      "y, 0.0143, 0.0063\n",
      "z, 0.0010, 0.0000\n"
     ]
    }
   ],
   "source": [
    "A,B,pi = initialize_random(N,M,sigma=.01)\n",
    "declaration1 = hmm()\n",
    "declaration1.fit(obs,A,B,pi,max_iter=300)\n",
    "\n",
    "# example of typical results for well converged HMM\n",
    "for i in range(len(declaration1.B)):\n",
    "    print(u\"{0}, {1:0.4f}, {2:0.4f}\".format(symbols[i], \n",
    "                                            declaration1.B[i,0], \n",
    "                                            declaration1.B[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the second column of B? It seems that the HMM has detected a vowel\n",
    "state and a consonant state, without any prior input from an English speaker. Interestingly,\n",
    "the whitespace character is grouped together with the vowels. A HMM can also detect the\n",
    "vowel/consonant distinction in other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Indeed, it look like the second column is vowels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "Repeat the previous calculation with 3 hidden states and again with 4 hidden\n",
    "states. Interpret/explain your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.0000, 0.3785, 0.0426\n",
      "a, 0.0000, 0.0602, 0.1616\n",
      "b, 0.0001, 0.0000, 0.0540\n",
      "c, 0.0433, 0.0000, 0.0344\n",
      "d, 0.0882, 0.0000, 0.0000\n",
      "e, 0.0614, 0.1955, 0.0312\n",
      "f, 0.0571, 0.0000, 0.0096\n",
      "g, 0.0435, 0.0000, 0.0033\n",
      "h, 0.0006, 0.1080, 0.0000\n",
      "i, 0.0000, 0.1074, 0.0590\n",
      "j, 0.0056, 0.0000, 0.0000\n",
      "k, 0.0040, 0.0006, 0.0004\n",
      "l, 0.0508, 0.0014, 0.0447\n",
      "m, 0.0385, 0.0000, 0.0194\n",
      "n, 0.0497, 0.0000, 0.1945\n",
      "o, 0.0000, 0.0970, 0.1146\n",
      "p, 0.0207, 0.0000, 0.0449\n",
      "q, 0.0000, 0.0018, 0.0000\n",
      "r, 0.1029, 0.0065, 0.0629\n",
      "s, 0.1311, 0.0018, 0.0558\n",
      "t, 0.2233, 0.0007, 0.0000\n",
      "u, 0.0000, 0.0337, 0.0573\n",
      "v, 0.0259, 0.0000, 0.0000\n",
      "w, 0.0281, 0.0000, 0.0096\n",
      "x, 0.0013, 0.0016, 0.0001\n",
      "y, 0.0225, 0.0052, 0.0000\n",
      "z, 0.0014, 0.0000, 0.0000\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "M = len(set(obs))\n",
    "A,B,pi = initialize_random(N,M,sigma=.01)\n",
    "declaration2 = hmm()\n",
    "declaration2.fit(obs,A,B,pi,max_iter=300)\n",
    "\n",
    "# example of typical results for well converged HMM\n",
    "for i in range(len(declaration2.B)):\n",
    "    print(u\"{0}, {1:0.4f}, {2:0.4f}, {3:0.4f}\".format(symbols[i], \n",
    "                                                      declaration2.B[i,0], \n",
    "                                                      declaration2.B[i,1],\n",
    "                                                      declaration2.B[i,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, my hypothesis is that the first column is last letters of words, because r,s,t,and y are all pretty popular (along with other characters). Second column is vowels (but a is somewhat \"missing\"). Third column is just everything else? Beginning and middle constants plus \"a\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.0925, 0.0412, 0.0541, 0.2984\n",
      "a, 0.0000, 0.0000, 0.0000, 0.1381\n",
      "b, 0.0000, 0.0220, 0.0392, 0.0000\n",
      "c, 0.0326, 0.0293, 0.0646, 0.0000\n",
      "d, 0.0995, 0.0709, 0.0082, 0.0000\n",
      "e, 0.0237, 0.0000, 0.0000, 0.2404\n",
      "f, 0.0012, 0.1053, 0.0000, 0.0000\n",
      "g, 0.0559, 0.0185, 0.0213, 0.0000\n",
      "h, 0.2632, 0.0188, 0.0000, 0.0000\n",
      "i, 0.0299, 0.0000, 0.0000, 0.1195\n",
      "j, 0.0074, 0.0041, 0.0000, 0.0000\n",
      "k, 0.0045, 0.0038, 0.0000, 0.0006\n",
      "l, 0.0383, 0.0920, 0.0176, 0.0000\n",
      "m, 0.0000, 0.0831, 0.0003, 0.0008\n",
      "n, 0.0122, 0.0107, 0.2940, 0.0051\n",
      "o, 0.0561, 0.0098, 0.0000, 0.1241\n",
      "p, 0.0000, 0.0794, 0.0008, 0.0006\n",
      "q, 0.0016, 0.0024, 0.0000, 0.0000\n",
      "r, 0.0165, 0.1971, 0.0483, 0.0000\n",
      "s, 0.0810, 0.1072, 0.1274, 0.0033\n",
      "t, 0.1391, 0.0197, 0.2884, 0.0042\n",
      "u, 0.0000, 0.0000, 0.0000, 0.0605\n",
      "v, 0.0046, 0.0404, 0.0000, 0.0000\n",
      "w, 0.0047, 0.0239, 0.0345, 0.0000\n",
      "x, 0.0000, 0.0041, 0.0014, 0.0000\n",
      "y, 0.0355, 0.0136, 0.0000, 0.0044\n",
      "z, 0.0000, 0.0024, 0.0000, 0.0000\n"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "M = len(set(obs))\n",
    "A,B,pi = initialize_random(N,M,sigma=.01)\n",
    "declaration3 = hmm()\n",
    "declaration3.fit(obs,A,B,pi,max_iter=300)\n",
    "\n",
    "# example of typical results for well converged HMM\n",
    "for i in range(len(declaration3.B)):\n",
    "    print(u\"{0}, {1:0.4f}, {2:0.4f}, {3:0.4f}, {4:0.4f}\".format(symbols[i], \n",
    "                                                      declaration3.B[i,0], \n",
    "                                                      declaration3.B[i,1],\n",
    "                                                      declaration3.B[i,2],\n",
    "                                                      declaration3.B[i,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last column is vowels, and whitespace stuck with the vowels again. Again, I hypothesize that the first column is ending letter of word. No strong current beliefs about the second and third columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9\n",
    "\n",
    "Repeat the calculations for 2, and 3 hidden states for WarAndPeace.txt. Interpret/explain\n",
    "your results. Which Cyrillic characters appear to be vowels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.1610, 0.1669\n",
      "а, 0.0725, 0.0681\n",
      "б, 0.0156, 0.0145\n",
      "в, 0.0417, 0.0370\n",
      "г, 0.0164, 0.0191\n",
      "д, 0.0239, 0.0224\n",
      "е, 0.0742, 0.0615\n",
      "ж, 0.0095, 0.0073\n",
      "з, 0.0160, 0.0144\n",
      "и, 0.0546, 0.0525\n",
      "й, 0.0085, 0.0095\n",
      "к, 0.0289, 0.0317\n",
      "л, 0.0429, 0.0434\n",
      "м, 0.0239, 0.0219\n",
      "н, 0.0625, 0.0544\n",
      "о, 0.0893, 0.1029\n",
      "п, 0.0208, 0.0258\n",
      "р, 0.0361, 0.0356\n",
      "с, 0.0392, 0.0448\n",
      "т, 0.0432, 0.0504\n",
      "у, 0.0243, 0.0229\n",
      "ф, 0.0012, 0.0012\n",
      "х, 0.0062, 0.0070\n",
      "ц, 0.0031, 0.0028\n",
      "ч, 0.0122, 0.0110\n",
      "ш, 0.0072, 0.0059\n",
      "щ, 0.0035, 0.0022\n",
      "ъ, 0.0003, 0.0002\n",
      "ы, 0.0159, 0.0141\n",
      "ь, 0.0169, 0.0188\n",
      "э, 0.0021, 0.0032\n",
      "ю, 0.0060, 0.0054\n",
      "я, 0.0202, 0.0214\n",
      "ё, 0.0000, 0.0000\n"
     ]
    }
   ],
   "source": [
    "symbols, obs = prep_data('WarAndPeace.txt')\n",
    "N = 2\n",
    "M = len(set(obs))\n",
    "A,B,pi = initialize_random(N,M,sigma=.01)\n",
    "warandpeace1 = hmm()\n",
    "warandpeace1.fit(obs,A,B,pi,max_iter=300)\n",
    "\n",
    "# example of typical results for well converged HMM\n",
    "for i in range(len(warandpeace1.B)):\n",
    "    print(u\"{0}, {1:0.4f}, {2:0.4f}\".format(symbols[i], \n",
    "                                            warandpeace1.B[i,0], \n",
    "                                            warandpeace1.B[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.0979, 0.0426, 0.4196\n",
      "а, 0.0000, 0.1968, 0.0000\n",
      "б, 0.0327, 0.0000, 0.0103\n",
      "в, 0.0716, 0.0000, 0.0466\n",
      "г, 0.0372, 0.0000, 0.0142\n",
      "д, 0.0453, 0.0010, 0.0217\n",
      "е, 0.0000, 0.1535, 0.0486\n",
      "ж, 0.0188, 0.0000, 0.0050\n",
      "з, 0.0272, 0.0000, 0.0186\n",
      "и, 0.0000, 0.1427, 0.0095\n",
      "й, 0.0000, 0.0000, 0.0336\n",
      "к, 0.0581, 0.0000, 0.0316\n",
      "л, 0.0920, 0.0000, 0.0322\n",
      "м, 0.0433, 0.0000, 0.0249\n",
      "н, 0.1307, 0.0000, 0.0349\n",
      "о, 0.0000, 0.2672, 0.0026\n",
      "п, 0.0464, 0.0000, 0.0218\n",
      "р, 0.0865, 0.0000, 0.0124\n",
      "с, 0.0434, 0.0002, 0.0960\n",
      "т, 0.1042, 0.0000, 0.0286\n",
      "у, 0.0000, 0.0646, 0.0018\n",
      "ф, 0.0021, 0.0000, 0.0016\n",
      "х, 0.0122, 0.0000, 0.0077\n",
      "ц, 0.0076, 0.0000, 0.0004\n",
      "ч, 0.0202, 0.0000, 0.0149\n",
      "ш, 0.0147, 0.0000, 0.0038\n",
      "щ, 0.0076, 0.0000, 0.0000\n",
      "ъ, 0.0002, 0.0006, 0.0000\n",
      "ы, 0.0000, 0.0420, 0.0000\n",
      "ь, 0.0000, 0.0500, 0.0000\n",
      "э, 0.0000, 0.0000, 0.0098\n",
      "ю, 0.0000, 0.0029, 0.0175\n",
      "я, 0.0000, 0.0359, 0.0298\n",
      "ё, 0.0000, 0.0001, 0.0000\n"
     ]
    }
   ],
   "source": [
    "symbols, obs = prep_data('WarAndPeace.txt')\n",
    "N = 3\n",
    "M = len(set(obs))\n",
    "A,B,pi = initialize_random(N,M,sigma=.01)\n",
    "warandpeace2 = hmm()\n",
    "warandpeace2.fit(obs,A,B,pi,max_iter=300)\n",
    "\n",
    "# example of typical results for well converged HMM\n",
    "for i in range(len(warandpeace2.B)):\n",
    "    print(u\"{0}, {1:0.4f}, {2:0.4f}, {3:0.4f}\".format(symbols[i], \n",
    "                                                      warandpeace2.B[i,0], \n",
    "                                                      warandpeace2.B[i,1],\n",
    "                                                      warandpeace2.B[i,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Cryllic has three hidden states because both times I ran the N=2 one it doesn't come up with results that make any sense. But it seems that in the N=3 the second column found the vowels\\."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
