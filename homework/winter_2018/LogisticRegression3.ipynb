{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Run a multiclass (softmax) logistic regression on the scikit-learn digits dataset with the same train-test split we have used in the past. Experiment with different regularization parameters and choose the best. Justify your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k = -1 with accuracy of 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# Load digits dataset and split it up into test/train sets\n",
    "digits = datasets.load_digits()\n",
    "digits.keys()\n",
    "xtrain, xtest, ytrain, ytest = ms.train_test_split(digits['data'], \n",
    "                                                   digits['target'], \n",
    "                                                   test_size=.3)\n",
    "\n",
    "# iterate through a variety of magnitudes for C \n",
    "# and choose the C with highest accuracy\n",
    "accuracy = []\n",
    "for k in range(-10,11):\n",
    "    c = 10**k\n",
    "    # train and predict model for given c\n",
    "    model = LogisticRegression(multi_class='multinomial', \n",
    "                               solver='lbfgs', C=c)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ypredict = model.predict(xtest)\n",
    "    accuracy.append((k,np.mean(ypredict==ytest)))\n",
    "    \n",
    "# sort accuracies to find the best value of c\n",
    "accuracy = sorted(accuracy, key=lambda x: x[1], reverse=True)\n",
    "print(\"Best value of k = {} with accuracy of {}\".format(accuracy[0][0], \n",
    "                                                        accuracy[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Install Keras and tensorflow on your computer. For most of you this can be done in one line with `conda install keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comes pre-installed on lab computers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "Load the full MNIST dataset with keras's pre-chosen train-test split using\n",
    "from `keras.datasets import mnist`\n",
    "`(X_train, y_train), (X_test, y_test) = mnist.load_data()`\n",
    "and flatten the images into a single vector\n",
    "`input_dim = 784 #28*28`\n",
    "`X_train = X_train.reshape(60000, input_dim)`\n",
    "`X_test = X_test.reshape(10000, input_dim)`\n",
    "You may also need to convert the data to floats (they come as ints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11247616/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Load MNIST data and shape everything appropriately\n",
    "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "input_dim = 784\n",
    "xtrain = xtrain.reshape(60000, input_dim)\n",
    "xtest = xtest.reshape(10000, input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Construct the multi-class matrix from y\n",
    "`from keras.utils import np_utils\n",
    "Y = np_utils.to_categorical(y, nb_classes)`\n",
    "and build a softmax classifier\n",
    "`from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "output_dim = 10 # number of classes\n",
    "soft = Sequential()\n",
    "soft.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
    "soft.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the logstic regression model using softmax with Keras, which means 'horn' in Greek\n",
    "output_dim = 10\n",
    "soft = Sequential()\n",
    "soft.add(Dense(output_dim, \n",
    "               input_dim=input_dim, \n",
    "               activation='softmax'))\n",
    "soft.compile(optimizer='sgd', \n",
    "             loss='categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "ytest = np_utils.to_categorical(ytest, output_dim)\n",
    "ytrain = np_utils.to_categorical(ytrain, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Experiment with various parameters, including different batch sizes and numbers of epochs to find the combination that gives the best results on the MNIST data set:\n",
    "`soft.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through batch sizes and number of epochs as determined below\n",
    "batch_sizes = [2**k for k in range(6,14)]\n",
    "epochs = [k for k in range(5,36,5)]\n",
    "results = []\n",
    "for epoch in epochs:\n",
    "    for b_s in batch_sizes:\n",
    "        hist = soft.fit(xtrain, ytrain, batch_size=b_s, epochs=epoch,\n",
    "                        verbose=0, validation_data=(xtest, ytest))\n",
    "        # the results we will record are the accuracy and loss function value on the validation set\n",
    "        results.append((epoch, b_s, \n",
    "                        np.max(hist.history['val_acc']), \n",
    "                        np.min(hist.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results ordered by validation accuracy\n",
      "suggest that epochs=10 and batch_size=1024 is the best.\n",
      "The results ordered by validation loss\n",
      "suggest that epochs=10 and batch_size=1024 is the best.\n"
     ]
    }
   ],
   "source": [
    "# print which model set up worked best for me\n",
    "results = sorted(results, key=lambda x: x[2], reverse=True)\n",
    "print(\"The results ordered by validation accuracy\\nsuggest that epochs={} and batch_size={} is the best.\".format(results[0][0], results[0][1]))\n",
    "results = sorted(results, key=lambda x: x[3], reverse=False)\n",
    "print(\"The results ordered by validation loss\\nsuggest that epochs={} and batch_size={} is the best.\".format(results[0][0], results[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating through batch sizes equal to $2^k$ for $k$ in ${6, ... , 13}$ and epochs equal to $j$ for $j$ in ${5, 10, ... , 30, 35}$, both looking at the highest accuracy and the lowest loss has resulted in working with `batch_size = 1024` and `epochs = 10` is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "Identify a multi-class classification problem related to your final project, using your project data. Use a softmax regression and choose an appropriate regularization parameter and appropriate choices of other hyperparameters and training parameters. Clearly identify your final preferred model, and explain why you chose that over the other contenders. What conclusions can be drawn from your results about the original classification question you asked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k = -10 with accuracy of 0.4909840288511077\n"
     ]
    }
   ],
   "source": [
    "# Here I will use data from the American Housing Survey\n",
    "# because my project data doesn't work well for this stuff\n",
    "ahs = pd.read_csv('ahs_clean.csv')\n",
    "ahs = ahs[ahs['LOGVALUE']!=0]\n",
    "X = ahs[['LOGVALUE', 'LOT', 'UNITSF', 'BATHS', 'AGE', 'PORCH']]\n",
    "Y = ahs['BEDRMS']\n",
    "\n",
    "# We will be predicting the number of bedrooms from a house using\n",
    "# the above features\n",
    "\n",
    "# iterate through various values of C and choose the one that maximizes accuracy\n",
    "xtrain, xtest, ytrain, ytest = ms.train_test_split(X, Y, test_size=.3)\n",
    "accuracy = []\n",
    "for k in range(-10,11):\n",
    "    c = 10**k\n",
    "    # train and predict model for given c\n",
    "    model = LogisticRegression(multi_class='multinomial', \n",
    "                               solver='lbfgs', C=c)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ypredict = model.predict(xtest)\n",
    "    accuracy.append((k,np.mean(ypredict==ytest)))\n",
    "    \n",
    "# sort accuracies to find the best value of c\n",
    "accuracy = sorted(accuracy, key=lambda x: x[1], reverse=True)\n",
    "print(\"Best value of k = {} with accuracy of {}\".format(accuracy[0][0], \n",
    "                                                        accuracy[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k = -4 with accuracy of 0.49265842349304484\n"
     ]
    }
   ],
   "source": [
    "# We will be predicting the number of bedrooms from a house using\n",
    "# ALL of the features, so this is the kitchen sink model\n",
    "\n",
    "# iterate through various values of C and choose the one that maximizes accuracy\n",
    "xtrain, xtest, ytrain, ytest = ms.train_test_split(X, Y, test_size=.3)\n",
    "accuracy = []\n",
    "for k in range(-10,11):\n",
    "    c = 10**k\n",
    "    # train and predict model for given c\n",
    "    model = LogisticRegression(multi_class='multinomial', \n",
    "                               solver='lbfgs', C=c)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ypredict = model.predict(xtest)\n",
    "    accuracy.append((k,np.mean(ypredict==ytest)))\n",
    "    \n",
    "# sort accuracies to find the best value of c\n",
    "accuracy = sorted(accuracy, key=lambda x: x[1], reverse=True)\n",
    "print(\"Best value of k = {} with accuracy of {}\".format(accuracy[0][0], \n",
    "                                                        accuracy[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use my first model because it used the features that I felt seemed most reasonable to use to predict number of bedrooms and they are all features that shouldn't be incredibly difficult to gather on houses, thus it would be data that would be easy to use in a model being used in production to actually guess the number of bedrooms in a house. However, I doubt that many people are particularly concerned about predict the number of bedrooms in a house accurately. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
