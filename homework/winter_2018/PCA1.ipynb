{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Apply PCA to the cancer dataset to reduce the dimension of the feature space to each of 15, 10, and 5.    Are there any features or combinations of features for which PCA is not a suitable method to use?  Explain.  WARNING: remember to center your data (subtract the mean) and also normalize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data set\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# center and normalize the data\n",
    "X = X - X.mean(axis=0)\n",
    "X = X / X.std(axis=0)\n",
    "U, s, Vh = la.svd(X)\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y, test_size=.3)\n",
    "    \n",
    "xtrain5, xtest5 = xtrain.dot(Vh[:5].T), xtest.dot(Vh[:5].T)\n",
    "xtrain10, xtest10 = xtrain.dot(Vh[:10].T), xtest.dot(Vh[:10].T)\n",
    "xtrain15, xtest15 = xtrain.dot(Vh[:15].T), xtest.dot(Vh[:15].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.097064 -2.073335  1.269934  0.984375  1.568466  3.283515  2.652874   \n",
       "1  1.829821 -0.353632  1.685955  1.908708 -0.826962 -0.487072 -0.023846   \n",
       "2  1.579888  0.456187  1.566503  1.558884  0.942210  1.052926  1.363478   \n",
       "3 -0.768909  0.253732 -0.592687 -0.764464  3.283553  3.402909  1.915897   \n",
       "4  1.750297 -1.151816  1.776573  1.826229  0.280372  0.539340  1.371011   \n",
       "\n",
       "         7         8         9     ...           20        21        22  \\\n",
       "0  2.532475  2.217515  2.255747    ...     1.886690 -1.359293  2.303601   \n",
       "1  0.548144  0.001392 -0.868652    ...     1.805927 -0.369203  1.535126   \n",
       "2  2.037231  0.939685 -0.398008    ...     1.511870 -0.023974  1.347475   \n",
       "3  1.451707  2.867383  4.910919    ...    -0.281464  0.133984 -0.249939   \n",
       "4  1.428493 -0.009560 -0.562450    ...     1.298575 -1.466770  1.338539   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0  2.001237  1.307686  2.616665  2.109526  2.296076  2.750622  1.937015  \n",
       "1  1.890489 -0.375612 -0.430444 -0.146749  1.087084 -0.243890  0.281190  \n",
       "2  1.456285  0.527407  1.082932  0.854974  1.955000  1.152255  0.201391  \n",
       "3 -0.550021  3.394275  3.893397  1.989588  2.175786  6.046041  4.935010  \n",
       "4  1.220724  0.220556 -0.313395  0.613179  0.729259 -0.868353 -0.397100  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#are any features or combinations of features not PCA-suitable?\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, all are suitable because they are all numeric/continous data and can be centered and normalized by their standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Apply three of your favorite classification methods to the full cancer data set and also to the PCA-reduced data.  Analyze and evaluate the performance (time and accuracy) for each combination.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "start = time.time()\n",
    "log_reg.fit(xtrain,ytrain)\n",
    "lr30_time = round(time.time() - start, 5)\n",
    "lr30_acc = round((log_reg.predict(xtest) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "log_reg.fit(xtrain5,ytrain)\n",
    "lr5_time = round(time.time() - start, 5)\n",
    "lr5_acc = round((log_reg.predict(xtest5) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "log_reg.fit(xtrain10,ytrain)\n",
    "lr10_time = round(time.time() - start, 5)\n",
    "lr10_acc = round((log_reg.predict(xtest10) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "log_reg.fit(xtrain15,ytrain)\n",
    "lr15_time = round(time.time() - start, 5)\n",
    "lr15_acc = round((log_reg.predict(xtest15) == ytest).mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "svc = SVC()\n",
    "start = time.time()\n",
    "svc.fit(xtrain,ytrain)\n",
    "svc30_time = round(time.time() - start, 5)\n",
    "svc30_acc = round((svc.predict(xtest) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "svc.fit(xtrain5,ytrain)\n",
    "svc5_time = round(time.time() - start, 5)\n",
    "svc5_acc = round((svc.predict(xtest5) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "svc.fit(xtrain10,ytrain)\n",
    "svc10_time = round(time.time() - start, 5)\n",
    "svc10_acc = round((svc.predict(xtest10) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "svc.fit(xtrain15,ytrain)\n",
    "svc15_time = round(time.time() - start, 5)\n",
    "svc15_acc = round((svc.predict(xtest15) == ytest).mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "start = time.time()\n",
    "gnb.fit(xtrain,ytrain)\n",
    "gnb30_time = round(time.time() - start, 5)\n",
    "gnb30_acc = round((gnb.predict(xtest) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "gnb.fit(xtrain5,ytrain)\n",
    "gnb5_time = round(time.time() - start, 5)\n",
    "gnb5_acc = round((gnb.predict(xtest5) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "gnb.fit(xtrain10,ytrain)\n",
    "gnb10_time = round(time.time() - start, 5)\n",
    "gnb10_acc = round((gnb.predict(xtest10) == ytest).mean(), 4)\n",
    "\n",
    "start = time.time()\n",
    "gnb.fit(xtrain15,ytrain)\n",
    "gnb15_time = round(time.time() - start, 5)\n",
    "gnb15_acc = round((gnb.predict(xtest15) == ytest).mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Results are printed as \"time / accuracy\"\n",
      "\t\tFull Data\t\t15-dimensional\t\t10-dimensional\t\t5-dimensional\n",
      "Logistic Reg\t0.00252 / 0.9708\t0.00158 / 0.9825\t0.00128 / 0.9649\t0.00097 / 0.9649\n",
      "SVM\t\t0.00442 / 0.9766\t0.00478 / 0.9649\t0.00541 / 0.9591\t0.0057 / 0.9591\n",
      "Naive Bayes\t0.00126 / 0.9123\t0.00052 / 0.8889\t0.00086 / 0.9123\t0.00086 / 0.9415\n"
     ]
    }
   ],
   "source": [
    "#analyze results\n",
    "print('All Results are printed as \"time / accuracy\"')\n",
    "print('\\t\\tFull Data\\t\\t15-dimensional\\t\\t10-dimensional\\t\\t5-dimensional')\n",
    "print('Logistic Reg\\t{} / {}\\t{} / {}\\t{} / {}\\t{} / {}'.format(lr30_time, lr30_acc, lr15_time, lr15_acc, lr10_time, lr10_acc, lr5_time, lr5_acc))\n",
    "print('SVM\\t\\t{} / {}\\t{} / {}\\t{} / {}\\t{} / {}'.format(svc30_time, svc30_acc, svc15_time, svc15_acc, svc10_time, svc10_acc, svc5_time, svc5_acc))\n",
    "print('Naive Bayes\\t{} / {}\\t{} / {}\\t{} / {}\\t{} / {}'.format(gnb30_time, gnb30_acc, gnb15_time, gnb15_acc, gnb10_time, gnb10_acc, gnb5_time, gnb5_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Find some aspect of your final project for which PCA is an appropriate dimension-reduction method.  Apply PCA and analyze the results and performance.  Compare to your results without PCA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select data that I will reduce\n",
    "default = pd.read_csv('default.csv')\n",
    "to_reduce = default[['LIMIT_BAL','BILL_AMT1','BILL_AMT2','BILL_AMT3',\n",
    "             'BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1',\n",
    "             'PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']].values\n",
    "\n",
    "# center and normalize the data\n",
    "X = to_reduce - to_reduce.mean(axis=0)\n",
    "X = X / X.std(axis=0)\n",
    "U, s, Vh = la.svd(X)\n",
    "\n",
    "#xtrain,xtest,ytrain,ytest = train_test_split(X,y, test_size=.3)\n",
    "x5 = X.dot(Vh[:5].T)\n",
    "\n",
    "\"\"\"added_data = default[['SEX', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4','PAY_5', 'PAY_6',\n",
    "       'educ: _1', 'educ: _2', 'educ: _3', 'educ: _4', 'educ: _5',\n",
    "       'educ: _6', 'marr: _1', 'marr: _2', 'marr: _3']].values\n",
    "pca_data = np.concatenate((x5, added_data), axis=1)\n",
    "original_data = np.concatenate((to_reduce, added_data), axis=1)\n",
    "\"\"\"\n",
    "y = default['default']\n",
    "\n",
    "pca_train, pca_test, original_train, original_test, ytrain, ytest = train_test_split(x5, to_reduce, y, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compare results\n",
    "model = LogisticRegression()\n",
    "start = time.time()\n",
    "model.fit(pca_train, ytrain)\n",
    "pca_time = time.time() - start\n",
    "pca_acc = (model.predict(pca_test) == ytest).mean()\n",
    "\n",
    "start = time.time()\n",
    "model.fit(original_train, ytrain)\n",
    "original_time = time.time() - start\n",
    "original_acc = (model.predict(original_test) == ytest).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tTime\t\t\tAccuracy\n",
      "Non-reduced\t0.0726931095123291\t0.7753333333333333\n",
      "Reduced\t\t0.022054672241210938\t0.7753333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\tTime\\t\\t\\tAccuracy\\nNon-reduced\\t{}\\t{}\\nReduced\\t\\t{}\\t{}\".format(original_time, original_acc, pca_time, pca_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy was the same between the two models but the PCA data was much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "Repeat what you did in the previous problem, but replacing PCA by a random projection. Try 5 different random projections and compare the results and performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = GaussianRandomProjection(n_components=5)\n",
    "\n",
    "#apply random projection 1\n",
    "X1 = transformer.fit_transform(X)\n",
    "x1train, x1test, ytrain, ytest = train_test_split(X1,y, test_size=.3)\n",
    "start = time.time()\n",
    "model.fit(x1train, ytrain)\n",
    "x1time = time.time() - start\n",
    "x1acc = (model.predict(x1test) == ytest).mean()\n",
    "\n",
    "#apply random projection 2\n",
    "X2 = transformer.fit_transform(X)\n",
    "x2train, x2test, ytrain, ytest = train_test_split(X2,y, test_size=.3)\n",
    "start = time.time()\n",
    "model.fit(x2train, ytrain)\n",
    "x2time = time.time() - start\n",
    "x2acc = (model.predict(x2test) == ytest).mean()\n",
    "\n",
    "#apply random projection 3\n",
    "X3 = transformer.fit_transform(X)\n",
    "x3train, x3test, ytrain, ytest = train_test_split(X3,y, test_size=.3)\n",
    "start = time.time()\n",
    "model.fit(x3train, ytrain)\n",
    "x3time = time.time() - start\n",
    "x3acc = (model.predict(x3test) == ytest).mean()\n",
    "\n",
    "#apply random projection 4\n",
    "X4 = transformer.fit_transform(X)\n",
    "x4train, x4test, ytrain, ytest = train_test_split(X4,y, test_size=.3)\n",
    "start = time.time()\n",
    "model.fit(x4train, ytrain)\n",
    "x4time = time.time() - start\n",
    "x4acc = (model.predict(x4test) == ytest).mean()\n",
    "\n",
    "#apply random projection 5\n",
    "X5 = transformer.fit_transform(X)\n",
    "x5train, x5test, ytrain, ytest = train_test_split(X5,y, test_size=.3)\n",
    "start = time.time()\n",
    "model.fit(x5train, ytrain)\n",
    "x5time = time.time() - start\n",
    "x5acc = (model.predict(x5test) == ytest).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tTime\t\t\tAccuracy\n",
      "Random Projection 1\t0.03597593307495117\t0.7775555555555556\n",
      "Random Projection 2\t0.029416561126708984\t0.7812222222222223\n",
      "Random Projection 3\t0.027154922485351562\t0.7722222222222223\n",
      "Random Projection 4\t0.02589702606201172\t0.7796666666666666\n",
      "Random Projection 5\t0.027820110321044922\t0.7792222222222223\n"
     ]
    }
   ],
   "source": [
    "#compare results and performance\n",
    "print(\"\\t\\t\\tTime\\t\\t\\tAccuracy\")\n",
    "i = 1\n",
    "for result in [[x1time,x1acc],[x2time, x2acc],[x3time, x3acc],[x4time, x4acc],[x5time,x5acc]]:\n",
    "    print(\"Random Projection {}\\t{}\\t{}\".format(i, result[0], result[1]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy was just as good but the time to train the model wasn't any different from the PCA data (which makes sense, it is all the same number of dimensions). However, we aren't comparing time it takes to randomly project vs. do PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
