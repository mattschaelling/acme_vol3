{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 3: Pandas 1\n",
    "    <Name>\n",
    "    <Class>\n",
    "    <Date>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Create a pandas `Series` where the index labels are the even integers $0,2,\\ldots,100$ and the entries are the label squared minus one.\n",
    "That is, the $n$th entry in the `Series` is $n^2 âˆ’ 1$ and has label $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Suppose you make an investment of $d$ dollars in a particularly volatile stock.\n",
    "Every day the value of your stock goes up by \\$$1$ with probability $p$, or down by \\$$1$ with probability $1-p$ (this is an example of a _random walk_).\n",
    "\n",
    "Write a function that accepts a probability parameter $p$ and an initial amount of money $d$, defaulting to $100$.\n",
    "Use `pd.date_range()` to create an index of the days from 1 January 2000 to 31 December 2000.\n",
    "Simulate the daily change of the stock by making one draw from a Bernoulli distribution with parameter $p$ (a binomial distribution with one draw) for each day.\n",
    "Store the draws in a pandas `Series` with the date index and set the first draw to the initial amount $d$.\n",
    "Sum the entries cumulatively to get the stock value by day.\n",
    "Set any negative values to $0$, then plot the series.\n",
    "\n",
    "Call your function with a few different values of $p$ and $d$ to observe the different possible kinds of behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_walk(p, initial_fund=100):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call your function a few times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Use pandas to perform the following SQL query on the ''tables'' constructed below.\n",
    "\n",
    "`SELECT ID, Name from studentInfo WHERE Age > 19 AND Sex = 'M'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = ['Mylan', 'Regan', 'Justin', 'Jess', 'Jason', 'Remi', 'Matt', 'Alexander', 'JeanMarie']\n",
    "sex = ['M', 'F', 'M', 'F', 'M', 'F', 'M', 'M', 'F']\n",
    "age = [20, 21, 18, 22, 19, 20, 20, 19, 20]\n",
    "rank = ['Sp', 'Se', 'Fr', 'Se', 'Sp', 'J', 'J', 'J', 'Se']\n",
    "ID = range(9)\n",
    "aid = ['y', 'n', 'n', 'y', 'n', 'n', 'n', 'y', 'n']\n",
    "GPA = [3.8, 3.5, 3.0, 3.9, 2.8, 2.9, 3.8, 3.4, 3.7]\n",
    "mathID = [0, 1, 5, 6, 3]\n",
    "mathGd = [4.0, 3.0, 3.5, 3.0, 4.0]\n",
    "major = ['y', 'n', 'y', 'n', 'n']\n",
    "studentInfo = pd.DataFrame({'ID': ID, 'Name': name, 'Sex': sex, 'Age': age, 'Class': rank})\n",
    "otherInfo = pd.DataFrame({'ID': ID, 'GPA': GPA, 'Financial_Aid': aid})\n",
    "mathInfo = pd.DataFrame({'ID': mathID, 'Grade': mathGd, 'Math_Major': major})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Using a join operation, create a DataFrame containing the ID, age, and GPA of all male individuals. You ought to be able to accomplish this in one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "The file `crime_data.csv` contains data on types of crimes committed in the United States from 1960 to 2016.\n",
    "- Load the data into a pandas \\li{DataFrame}, using the column names in the file and the column titled\n",
    "`\"Year\"` as the index.\n",
    "Make sure to skip lines that don't contain data.\n",
    "- Insert a new column into the data frame that contains the crime rate by year (the ratio of `\"Total\"` column\n",
    "to the `\"Population\"` column).\n",
    "- Plot the crime rate as a function of the year.\n",
    "- List the 5 years with the highest crime rate in descending order.\n",
    "- Calculate the average number of total crimes as well as burglary crimes between 1960 and 2012.\n",
    "- Find the years for which the total number of crimes was below average, but the number of burglaries\n",
    "was above average.\n",
    "- Plot the number of murders as a function of the population.\n",
    "- Select the Population, Violent, and Robbery columns for all years in the 1980s, and save\n",
    "this smaller data frame to a CSV file `crime_subset.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "In 1912 the RMS _Titanic_ sank after colliding with an iceberg.\n",
    "The file `titanic.csv` contains data on the incident.\n",
    "Each row represents a different passenger, and the columns describe various features of the passengers (age, sex, whether or not they survived, etc.)\n",
    "\n",
    "Start by cleaning the data.\n",
    "- Read the data into a `DataFrame`.\n",
    "    Use the first row of the file as the column labels, but do not use any of the columns as the index.\n",
    "- Drop the columns `\"Sibsp\"`, `\"Parch\"`, `\"Cabin\"`, `\"Boat\"`, `\"Body\"`, and `\"home.dest\"`.\n",
    "- Drop any entries without data in the `\"Survived\"` column, then change the remaining entries to `True` or `False` (they start as 1 or 0).\n",
    "- Replace null entries in the `\"Age\"` column with the average age.\n",
    "- Save the new `DataFrame` as `titanic_clean.csv`.\n",
    "\n",
    "Next, answer the following questions.\n",
    "- How many people survived? What percentage of passengers survived?\n",
    "- What was the average price of a ticket? How much did the most expensive ticket cost?\n",
    "- How old was the oldest survivor? How young was the youngest survivor? What about non-survivors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
